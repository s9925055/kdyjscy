{
    "collab_server" : "",
    "contents" : "source('.\\\\R\\\\load_data.R', encoding = 'UTF-8')\nlibrary(wordcloud2)\n\nsummary(kdyjscy_comment$year)\nkdyjscy_comment$Comment %<>% str_replace_all(., '[:punct:a-zA-Z0-9]', '')\nfilter_word = c('酸汤', '没有', '有点', '感觉', '两个', '比较', '这家', '下次', '一直', '非常', '鱼片', '鱼肉', '每次', '酸菜', '里面', '一条', '真的', '觉得', '一个', '有家', '生意', '以后', '以前', '时间', '一家', '上菜', '个人', '总体', '知道', '吃', '鱼', '点', '店', '没', '会', '说', '菜', '汤', '斤', '完', '吃鱼', '吃酸菜鱼', '想', '送', '多次', '吃完','两个吃', '量', '一点', '太', '吃吃', '已经', '一起', '一次', '超级', '态度', '地方', '做', '三个', '最后', '微', '家', '小时', '这家店', '蛮', '现在', '今天', '可能', '少', '位置', '之前', '久', '吃味道', '喝', '不用', '不会', '酸菜鱼味道', '店里', '希望', '好多', '带', '需要', '起来', '一下', '不能', '不够', '爱', '没吃', '选', '东西', '左右', '一份', '鱼味道', '速度', '基本', '真心', '找', '适合', '不好', '人点', '吃饭', '过来', '里', '后来', '挑', '点酸汤', '建议', '更', '吃几次', '一条鱼', '应该', '选择', '菜品', '上来', '涮', '锅', '鱼吃', '一楼', '分钟', '加', '他家', '不要', '开', '够', '排', '斤鱼', '味', '继续', '煮', '好像', '一锅', '四个', '不到', '看到', '高', '这家酸菜鱼', '确实', '那家', '中', '只能', '消费', '本来', '大众', '没什么', '号', '发现', '负', '一家店', '几个', '吃酸汤', '其实', '吃一次', '斤黑鱼', '进去', '涮菜', '广场', '先', '半个', '一瓶', '还点', '换', '斤两', '大概', '负一楼', '估计', '过去', '一定', '不吃', '人', '元', '两个人点', '居然', '条', '一条斤', '半个小时', '分量', '机会', '坐', '刚', '走', '三斤鱼', '最好', '石路', '店家', '真是', '是不是', '问', '吃一条', '点菜', '上桌', '两次', '挺', '吃', '点', '卡', '位于', '人民商场负', '星座', '圆融', '地下', '国际', '大洋', '逛', '品种', '印象', '本来想', '鱼酸汤', '商场', '好找', '小哥', '空间', '约', '弯', '办', '楼下', '边上', '拌', '会员', '有家酸菜鱼吃', '吃有点', '好吃好吃', '感觉没有', '好好', '难得', '好吃吃', '不错价格')\nmixer <- worker(\"mix\", dict = '.\\\\dict\\\\jieba.dict.utf8', user = '.\\\\dict\\\\user.dict.utf8',\n                user_weight = 'max', stop_word = '.\\\\dict\\\\stop_words.utf8')\n\n# 总体词云----\nword_cloud_fun = function(text, min_num){\n  seg_comment <- lapply(text, segment, jiebar = mixer)\n  seg_comment %<>% filter_segment(., '团购|点评')\n  \n  t.token <- itoken(seg_comment)\n  t.vocab <- create_vocabulary(t.token, ngram = c(1,2))\n  pruned_vocab = prune_vocabulary(t.vocab, term_count_min = min_num)\n  Encoding(pruned_vocab$vocab$terms) = 'UTF-8'\n  word_cloud <- as.data.frame(pruned_vocab$vocab)\n  word_cloud %<>% subset(., .$doc_counts > 1)\n  word_cloud = word_cloud[,-3]\n  word_cloud$terms %<>% str_replace_all(., '_', '')\n  word_cloud %<>% group_by(., terms) %>% summarise(., terms_counts = max(terms_counts))\n  for(word in filter_word){\n    index = which(word_cloud$terms == word)\n    if(length(index) == 0) next\n    word_cloud %<>% .[-c(index), ]\n  }\n  word_cloud$rank = rank(word_cloud$terms_counts)\n  word_cloud$rank = max(word_cloud$rank) - word_cloud$rank + 1\n  word_cloud %<>% arrange(., desc(terms_counts))\n  return(word_cloud)\n}\nwc_all = word_cloud_fun(kdyjscy_comment$Comment, 10)\n# save(wc_all, file = 'D:\\\\work\\\\liutongbu\\\\kdyjscy\\\\shiny\\\\data\\\\wc_all.RData')\n\nwc_all$terms_counts = wc_all$terms_counts*100\nwordcloud2(wc_all[1:70, ], fontWeight = 100)\n# ----\n\n# 各年词云变动\ncomment_2015 = subset(kdyjscy_comment, year == 2015)\nwc_2015 = word_cloud_fun(comment_2015$Comment, 7)\nwc_2015$terms_counts = wc_2015$terms_counts*100\nwordcloud2(wc_2015[1:70, ], fontWeight = 100)\n\ncomment_2016 = subset(kdyjscy_comment, year == 2016)\nwc_2016 = word_cloud_fun(comment_2016$Comment, 7)\ncomment_2017 = subset(kdyjscy_comment, year == 2017)\nwc_2017 = word_cloud_fun(comment_2017$Comment, 5)\n\nmerge1 = left_join(wc_2017[1:700, ], wc_2016, by = c(\"terms\" = 'terms'))\nmerge2 = left_join(merge1,wc_2015, by = \"terms\",all.x = T)\nmerge2 = select(merge2, terms, contains(\"rank\"))\nmerge2 = merge2[-c(1:3), ]\n\nmerge2$rank.x[is.na(merge2$rank.x)] = max(wc_2017$rank)+1\nmerge2$rank.y[is.na(merge2$rank.y)] = max(wc_2016$rank)+1\nmerge2$rank[is.na(merge2$rank)] = max(wc_2015$rank)+1\n\nmerge2$rank.x <- 1-(merge2$rank.x/(max(wc_2017$rank)+1))\nmerge2$rank.y <- 1-(merge2$rank.y/(max(wc_2016$rank)+1))\nmerge2$rank <- 1-(merge2$rank/(max(wc_2015$rank)+1))\ncolnames(merge2) = c(\"terms\",\"rank_2017\",\"rank_2016\",\"rank_2015\")\n\nall_rank = cbind(merge2, merge2$rank_2016-merge2$rank_2015, merge2$rank_2017-merge2$rank_2016)\ncolnames(all_rank) = c(\"terms\",\"rank_2017\",\"rank_2016\",\"rank_2015\",\"diff16_15\",\"diff17_16\")\nall_rank$absDiff = abs(all_rank$diff16_15) + abs(all_rank$diff17_16)\nall_rank$trueDiff = all_rank$diff16_15 + all_rank$diff17_16\n# save(all_rank, file = 'D:\\\\work\\\\liutongbu\\\\kdyjscy\\\\shiny\\\\data\\\\all_rank.RData')\n# 变动幅度排序(无论正负)\nall_rank1 = arrange(all_rank, desc(absDiff))[1:20, ]\nggplot(all_rank1, aes(x=reorder(terms, desc(absDiff)), y=absDiff)) + geom_bar(stat = 'identity') + theme(axis.text.x = element_text(face = \"bold\",angle = 90))\n# 上升最多\nall_rank1 = arrange(all_rank, desc(trueDiff))[1:20, ]\nggplot(all_rank1, aes(x=reorder(terms, desc(trueDiff)), y=trueDiff)) + geom_bar(stat = 'identity') + theme(axis.text.x = element_text(face = \"bold\",angle = 90))\n# 下降最多\nall_rank1 = arrange(all_rank, trueDiff)[1:20, ]\nggplot(all_rank1, aes(x=reorder(terms, desc(abs(trueDiff))), y=abs(trueDiff))) + geom_bar(stat = 'identity') + theme(axis.text.x = element_text(face = \"bold\",angle = 90))\n\n# # 排行 with 三个年度\n# all_rank2 = arrange(all_rank, desc(absDiff))[1:20, ] %>% .[, c(1:4)] %>% melt(., id = 'terms')\n# ggplot(data=all_rank2, aes(x = reorder(terms, desc(value)), y = value, fill = variable)) +\n#   geom_bar(stat=\"identity\")+\n#   theme(axis.text.x = element_text(face = \"bold\",size= 9,angle = 90,hjust=1, vjust=.3)) + labs(x = \" \")\n",
    "created" : 1502941210416.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "10|41|32|0|\n",
    "hash" : "373110367",
    "id" : "551242BB",
    "lastKnownWriteTime" : 1503304754,
    "last_content_update" : 1503304754067,
    "path" : "D:/work/liutongbu/kdyjscy/R/wordCloud_brand_comment.R",
    "project_path" : "R/wordCloud_brand_comment.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}