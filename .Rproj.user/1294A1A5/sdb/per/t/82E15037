{
    "collab_server" : "",
    "contents" : "library(wordcloud2)\n\nbrandname = c('iwill', 'holiland', 'efdc', 'gb', 'cfxb')\nfilepath = 'C:\\\\work\\\\crawler\\\\output\\\\iwill\\\\'\noutput_path = '.\\\\output\\\\'\ni=1\n\nfilter_word = c('酸汤', '没有', '有点', '感觉', '两个', '比较', '这家', '下次', '一直', '非常', '鱼片', '鱼肉', '每次', '酸菜', '里面', '一条', '真的', '觉得', '一个', '有家', '生意', '以后', '以前', '时间', '一家', '上菜', '个人', '总体', '知道', '吃', '鱼', '点', '店', '没', '会', '说', '菜', '汤', '斤', '完', '吃鱼', '吃酸菜鱼', '想', '送', '多次', '吃完','两个吃', '量', '一点', '太', '吃吃', '已经', '一起', '一次', '超级', '态度', '地方', '做', '三个', '最后', '微', '家', '小时', '这家店', '蛮', '现在', '今天', '可能', '少', '位置', '之前', '久', '吃味道', '喝', '不用', '不会', '酸菜鱼味道', '店里', '希望', '好多', '带', '需要', '起来', '一下', '不能', '不够', '爱', '没吃', '选', '东西', '左右', '一份', '鱼味道', '速度', '基本', '真心', '找', '适合', '不好', '人点', '吃饭', '过来', '里', '后来', '挑', '点酸汤', '建议', '更', '吃几次', '一条鱼', '应该', '选择', '菜品', '上来', '涮', '锅', '鱼吃', '一楼', '分钟', '加', '他家', '不要', '开', '够', '排', '斤鱼', '味', '继续', '煮', '好像', '一锅', '四个', '不到', '看到', '高', '这家酸菜鱼', '确实', '那家', '中', '只能', '消费', '本来', '大众', '没什么', '号', '发现', '负', '一家店', '几个', '吃酸汤', '其实', '吃一次', '斤黑鱼', '进去', '涮菜', '广场', '先', '半个', '一瓶', '还点', '换', '斤两', '大概', '负一楼', '估计', '过去', '一定', '不吃', '人', '元', '两个人点', '居然', '条', '一条斤', '半个小时', '分量', '机会', '坐', '刚', '走', '三斤鱼', '最好', '石路', '店家', '真是', '是不是', '问', '吃一条', '点菜', '上桌', '两次', '挺', '吃', '点', '卡', '位于', '人民商场负', '星座', '圆融', '地下', '国际', '大洋', '逛', '品种', '印象', '本来想', '鱼酸汤', '商场', '好找', '小哥', '空间', '约', '弯', '办', '楼下', '边上', '拌', '会员', '有家酸菜鱼吃', '吃有点', '好吃好吃', '感觉没有', '好好', '难得', '好吃吃', '不错价格', '特意', '决定')\nmixer <- worker(\"mix\", dict = '.\\\\dict\\\\jieba.dict.utf8', user = '.\\\\dict\\\\user.dict.utf8',\n                user_weight = 'max', stop_word = '.\\\\dict\\\\stop_words.utf8')\nword_cloud_fun = function(text, min_num){\n  seg_comment <- lapply(text, segment, jiebar = mixer)\n  seg_comment %<>% filter_segment(., '团购|点评|.{1}')\n  \n  t.token <- itoken(seg_comment)\n  t.vocab <- create_vocabulary(t.token, ngram = c(1,2))\n  pruned_vocab = prune_vocabulary(t.vocab, term_count_min = min_num)\n  Encoding(pruned_vocab$term) = 'UTF-8'\n  word_cloud <- as.data.frame(pruned_vocab)\n  word_cloud %<>% subset(., .$doc_count > 1)\n  word_cloud = word_cloud[,-3]\n  word_cloud$term %<>% str_replace_all(., '_', '')\n  word_cloud %<>% group_by(., term) %>% summarise(., term_count = max(term_count))\n  for(word in filter_word){\n    index = which(word_cloud$term == word)\n    if(length(index) == 0) next\n    word_cloud %<>% .[-c(index), ]\n  }\n  word_cloud$rank = rank(word_cloud$term_count)\n  word_cloud$rank = max(word_cloud$rank) - word_cloud$rank + 1\n  word_cloud %<>% arrange(., desc(term_count))\n  return(word_cloud)\n}\n# start ----\nload(paste0(filepath, brandname[i], '_comment_sen.RData'))\ncomment = get(paste0(brandname[i], '_comment'))\n\n\n# 总体词云----\nwc_all = word_cloud_fun(comment$Comment, 2)\nsave(wc_all, file = paste0(output_path, brandname[i], '_wc_all.RData'))\n# ----\n\n# 各年词云变动\ncomment_2015 = subset(comment, year == 2015)\nwc_2015 = word_cloud_fun(comment_2015$Comment, 7)\ncomment_2016 = subset(comment, year == 2016)\nwc_2016 = word_cloud_fun(comment_2016$Comment, 7)\ncomment_2017 = subset(comment, year == 2017)\nwc_2017 = word_cloud_fun(comment_2017$Comment, 5)\n\nmerge1 = left_join(wc_2017[1:700, ], wc_2016, by = c(\"term\" = 'term'))\nmerge2 = left_join(merge1,wc_2015, by = \"term\",all.x = T)\nmerge2 = select(merge2, term, contains(\"rank\"))\nmerge2 %<>% na.omit(.)\n# merge2 = merge2[-c(1:3), ]\n\nmerge2$rank.x[is.na(merge2$rank.x)] = max(wc_2017$rank)+1\nmerge2$rank.y[is.na(merge2$rank.y)] = max(wc_2016$rank)+1\nmerge2$rank[is.na(merge2$rank)] = max(wc_2015$rank)+1\n\nmerge2$rank.x <- 1-(merge2$rank.x/(max(wc_2017$rank)+1))\nmerge2$rank.y <- 1-(merge2$rank.y/(max(wc_2016$rank)+1))\nmerge2$rank <- 1-(merge2$rank/(max(wc_2015$rank)+1))\ncolnames(merge2) = c(\"terms\",\"rank_2017\",\"rank_2016\",\"rank_2015\")\n\nall_rank = cbind(merge2, merge2$rank_2016-merge2$rank_2015, merge2$rank_2017-merge2$rank_2016)\ncolnames(all_rank) = c(\"terms\",\"rank_2017\",\"rank_2016\",\"rank_2015\",\"diff16_15\",\"diff17_16\")\nall_rank$absDiff = abs(all_rank$diff16_15) + abs(all_rank$diff17_16)\nall_rank$trueDiff = all_rank$diff16_15 + all_rank$diff17_16\nsave(all_rank, file = paste0(output_path, brandname[i], '_all_rank.RData'))\n# ----\ni = i+1\n# # 变动幅度排序(无论正负)\n# all_rank1 = arrange(all_rank, desc(absDiff))[1:20, ]\n# ggplot(all_rank1, aes(x=reorder(terms, desc(absDiff)), y=absDiff)) + geom_bar(stat = 'identity') + theme(axis.text.x = element_text(face = \"bold\",angle = 90))\n# # 上升最多\n# all_rank1 = arrange(all_rank, desc(trueDiff))[1:20, ]\n# ggplot(all_rank1, aes(x=reorder(terms, desc(trueDiff)), y=trueDiff)) + geom_bar(stat = 'identity') + theme(axis.text.x = element_text(face = \"bold\",angle = 90))\n# # 下降最多\n# all_rank1 = arrange(all_rank, trueDiff)[1:20, ]\n# ggplot(all_rank1, aes(x=reorder(terms, desc(abs(trueDiff))), y=abs(trueDiff))) + geom_bar(stat = 'identity') + theme(axis.text.x = element_text(face = \"bold\",angle = 90))",
    "created" : 1504158604333.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "10|41|32|0|\n",
    "hash" : "1302233895",
    "id" : "82E15037",
    "lastKnownWriteTime" : 1504158258,
    "last_content_update" : 1504158654678,
    "path" : "C:/work/liutongbu/kdyjscy/R/wordCloud_brand_comment.R",
    "project_path" : "R/wordCloud_brand_comment.R",
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}